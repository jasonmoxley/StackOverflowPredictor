# -*- coding: utf-8 -*-
"""StackOverflowPredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-4HwaXVK2WZONcvMm7gdVf8HOlDvIcrk
"""

import numpy as np
import pandas as pd
from bs4 import BeautifulSoup as bs

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.neural_network import MLPClassifier

df_train = pd.read_csv('https://media.githubusercontent.com/media/jasonmoxley/StackOverflowPredictor/main/train.csv')
df_valid = pd.read_csv('https://media.githubusercontent.com/media/jasonmoxley/StackOverflowPredictor/main/valid.csv')

#prints the first 5 rows of data frame
df_train.head()

#prints the first 5 rows of data frame
df_valid.head()

#adding spacing before and after each tag to ensure no two words are not seperated by a space when beautifulsoup removes the tags
def add_spacing(data):
  data = data.replace("<", " <")
  data = data.replace(">", "> ")
  return data

#remove excess spacing after beautifulsoup removes tags
def remove_spacing(data):
  data = data.replace("    ", " ")
  data = data.replace("   ", " ")
  data = data.replace("  ", " ")
  data = data.lstrip()
  data = data.rstrip()
  return data

#this function uses the BeautifulSoup library to convert html to text
def htmlToText(html_string):
  soup = bs(html_string)
  #replacing all the code tags with the word code
  for codeTag in soup.findAll('code'):
        codeTag.replaceWith(" code ")
  return soup.get_text()

def tagsToText(tags):
  tags = tags.replace("><", " ")
  tags = tags.replace("<", "")
  tags = tags.replace(">", "")
  tags = tags.lstrip()
  tags = tags.rstrip()
  return tags

#test for html to text functions
test = '''<p>this is a test</p><code>this should be replaced with "code"</code><p>this is a test</p>'''
test = add_spacing(test)
test = htmlToText(test)
test = remove_spacing(test)
print("Two outputs below should be the same")
print("this is a test code this is a test")
print(test)

test = '''<machine><learning>'''
test = tagsToText(test)
print("Two outputs below should be the same")
print("machine learning")
print(test)

#cleans data using the above functions into a move usable form
def process_data(data):
  #data is a pandas data frame
  data = data.drop(columns=['Id', 'CreationDate'])

  #these lines convert the body column from html to text
  data['Body'] = data['Body'].apply(add_spacing, 1)
  data['Body'] = data['Body'].apply(htmlToText, 1)
  data['Body'] = data['Body'].apply(remove_spacing, 1)

  data['Tags'] = data['Tags'].apply(tagsToText, 1)

  #combining the title and body columns
  data['Post'] = data['Title'] + ' ' + data['Body'] + ' ' + data['Tags']
  #removing any possible excess spacing
  data['Post'] = data['Post'].apply(remove_spacing, 1)
  #removing the title and body columns
  data = data.drop(columns=['Title', 'Body', 'Tags'])

  #converting the labels to numbers
  data['Label'] = data['Y'].map({'HQ':1, 'LQ_EDIT':2, 'LQ_CLOSE':3})
  #removing the old labels column
  data = data.drop(columns=['Y'])

  return data

#processing the training data
df_train = process_data(df_train)
df_train.head()

#processing the validation data
df_valid = process_data(df_valid)
df_valid.head()

hqWords = {}
lqWords = {}
lqCloseWords = {}
hqWordsList = []
lqWordsList = []
lqCloseWordsList = []

for index, row in df_train.iterrows():
  words = row['Post']
  words = words.split(' ')
  label = row['Label']
  for word in words:
    if label == 1:
      if hqWords.get(word):
        hqWords[word] += 1
      else:
        hqWords[word] = 1
    if label == 2:
      if lqWords.get(word):
        lqWords[word] += 1
      else:
        lqWords[word] = 1
    if label == 3:
      if lqCloseWords.get(word):
        lqCloseWords[word] += 1
      else:
        lqCloseWords[word] = 1

for word in sorted(hqWords, key=hqWords.get, reverse=True):
  hqWordsList.append(word)
  if len(hqWordsList) > 100:
    break
for word in sorted(lqWords, key=lqWords.get, reverse=True):
  lqWordsList.append(word)
  if len(lqWordsList) > 100:
    break
for word in sorted(lqCloseWords, key=lqCloseWords.get, reverse=True):
  lqCloseWordsList.append(word)
  if len(lqCloseWordsList) > 100:
    break

print("these are the 100 most common words for each label")
print("label: HQ")
print(hqWordsList)
print("label: LQ_Edit")
print(lqWordsList)
print("label: LQ_Close")
print(lqCloseWordsList)

#this demonstrates the importance of the tfidf vectorizer
#we are going to try both the count vectorizer and the tfidf vectorizer anyway for logistic regression and naive bayes
#tfidf vectorizer is a combination of the count vectorizer and tfidf term weighting

#seperating the posts and labels of the train data
train_posts = df_train['Post']
train_labels = df_train['Label']

#seperating the posts and labels of the validation data
valid_posts = df_valid['Post']
valid_labels = df_valid['Label']

vectorizor = TfidfVectorizer()
train_posts_tfidf = vectorizor.fit_transform(train_posts)
valid_posts_tfidf = vectorizor.transform(valid_posts)

vectorizor = CountVectorizer()
train_posts_count = vectorizor.fit_transform(train_posts)
valid_posts_count = vectorizor.transform(valid_posts)

lr_result = LogisticRegression(max_iter=4000).fit(train_posts_count, train_labels)
lr_classification_accuracy_count = lr_result.score(valid_posts_count, valid_labels) * 100
print('logistic regression classification accuracy: ' + str(lr_classification_accuracy_count) + '%')

lr_result = LogisticRegression(max_iter=200).fit(train_posts_tfidf, train_labels)
lr_classification_accuracy_tfidf = lr_result.score(valid_posts_tfidf, valid_labels) * 100
print('logistic regression classification accuracy using tf-idf vectors: ' + str(lr_classification_accuracy_tfidf) + '%')

nb_result = MultinomialNB().fit(train_posts_count, train_labels)
nb_classification_accuracy_count = nb_result.score(valid_posts_count, valid_labels) * 100
print('naive bayes classification accuracy: ' + str(nb_classification_accuracy_count) + '%')

nb_result_tfidf = MultinomialNB().fit(train_posts_tfidf, train_labels)
nb_classification_accuracy_tfidf = nb_result_tfidf.score(valid_posts_tfidf, valid_labels) * 100
print('naive bayes classification accuracy using tf-idf vectors: ' + str(nb_classification_accuracy_tfidf) + '%')

neural_net = MLPClassifier().fit(train_posts_tfidf, train_labels)
neural_net_accuracy = neural_net.score(valid_posts_tfidf, valid_labels) * 100
print('neural net classification accuracy: ' + str(neural_net_accuracy) + '%')